{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a52e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e814a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a2f42",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d487f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNeuron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CustomNeuron, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in2hidden = MimicLayer(input_size + hidden_size, hidden_size)\n",
    "        self.in2output = MimicLayer(input_size + hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden_state):\n",
    "        combined = torch.cat((x, hidden_state), 1)\n",
    "        hidden = torch.sigmoid(self.in2hidden(combined))\n",
    "        output = self.in2output(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f622b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class MimicLayer(nn.Module):\n",
    "    def __init__(self, size_in, size_out, dd_min=0.1, dd_max=1.0):\n",
    "        super().__init__()\n",
    "        self.size_in, self.size_out = size_in, size_out\n",
    "        \n",
    "        self.light_weights = nn.Parameter(torch.empty(size_out, size_in))\n",
    "        \n",
    "        dendrite_tensor = torch.empty(1)\n",
    "        nn.init.uniform_(dendrite_tensor, dd_min, dd_max)\n",
    "        self.register_buffer(\"dendrite_distance\", dendrite_tensor)  # fixed, not learnable\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.empty(size_out))\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.light_weights, a=math.sqrt(5))\n",
    "        \n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.light_weights)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        effective_weights = self.light_weights * self.dendrite_distance\n",
    "        return torch.matmul(x, effective_weights.T) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec4bd234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_arch.png'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchview import draw_graph\n",
    "model = CustomNeuron(2, 8, 1)\n",
    "hidden = model.init_hidden(1)\n",
    "graph = draw_graph(model, input_data=[torch.randn(1, 2), hidden])\n",
    "graph.visual_graph.render(\"model_arch\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b48f71df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        MimicLayer-1                    [-1, 8]               8\n",
      "        MimicLayer-2                    [-1, 1]               1\n",
      "================================================================\n",
      "Total params: 9\n",
      "Trainable params: 0\n",
      "Non-trainable params: 9\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = CustomNeuron(input_size=2, hidden_size=8, output_size=1).to(device)\n",
    "summary(model, [(2,), (8,)], device=str(device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a83c7c",
   "metadata": {},
   "source": [
    "### Training to see it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69261331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 1.7533\n",
      "Epoch 40, Loss: 1.0984\n",
      "Epoch 60, Loss: 1.0990\n",
      "Epoch 80, Loss: 0.8414\n",
      "Epoch 100, Loss: 0.5220\n",
      "Epoch 120, Loss: 0.4730\n",
      "Epoch 140, Loss: 0.5377\n",
      "Epoch 160, Loss: 0.5247\n",
      "Epoch 180, Loss: 0.4386\n",
      "Epoch 200, Loss: 0.4892\n",
      "Test input: tensor([[0.2000, 0.6000]])\n",
      "Predicted sum: 0.7605530023574829\n",
      "Actual sum: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "seq_len = 5\n",
    "input_dim = 2\n",
    "hidden_dim = 8\n",
    "output_dim = 1\n",
    "batch_size = 16\n",
    "\n",
    "model = CustomNeuron(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(200):\n",
    "    x_seq = torch.rand(seq_len, batch_size, input_dim)\n",
    "    y_seq = x_seq.sum(dim=2, keepdim=True)  # target: sum of two inputs\n",
    "\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    loss = 0\n",
    "\n",
    "    for t in range(seq_len):\n",
    "        out, hidden = model(x_seq[t], hidden)\n",
    "        loss += criterion(out, y_seq[t])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "test_x = torch.tensor([[0.2, 0.6]])\n",
    "hidden = model.init_hidden(1)\n",
    "out, _ = model(test_x, hidden)\n",
    "print(\"Test input:\", test_x)\n",
    "print(\"Predicted sum:\", out.item())\n",
    "print(\"Actual sum:\", test_x.sum().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53071c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
